import React, { useState, useEffect, useRef } from 'react';
import { 
  Mic, 
  Square, // Changed MicOff to Square for "Stop"
  Languages, 
  Volume2, 
  RotateCcw, 
  Activity, 
  ShieldCheck, 
  Stethoscope, 
  Loader2,
  X,
  Copy,
  Check,
  Keyboard,
  Wand2 // Icon for AI processing
} from 'lucide-react';

// --- Configuration & Constants ---
const apiKey = "AIzaSyA4_qJyAfMtOCgT1_l05A7FMe87T3vTkao"; // API Key injected by environment

const LANGUAGES = [
  { code: 'en-US', name: 'English', flag: 'ðŸ‡ºðŸ‡¸' },
  { code: 'es-ES', name: 'Spanish', flag: 'ðŸ‡ªðŸ‡¸' },
  { code: 'fr-FR', name: 'French', flag: 'ðŸ‡«ðŸ‡·' },
  { code: 'de-DE', name: 'German', flag: 'ðŸ‡©ðŸ‡ª' },
  { code: 'zh-CN', name: 'Chinese (Mandarin)', flag: 'ðŸ‡¨ðŸ‡³' },
  { code: 'hi-IN', name: 'Hindi', flag: 'ðŸ‡®ðŸ‡³' },
  { code: 'ja-JP', name: 'Japanese', flag: 'ðŸ‡¯ðŸ‡µ' },
  { code: 'ar-SA', name: 'Arabic', flag: 'ðŸ‡¸ðŸ‡¦' },
  { code: 'pt-BR', name: 'Portuguese', flag: 'ðŸ‡§ðŸ‡·' },
  { code: 'ru-RU', name: 'Russian', flag: 'ðŸ‡·ðŸ‡º' },
];

const DISCLAIMER = "This is an AI-assisted translation tool. Always verify critical medical information with a certified human interpreter.";

// --- Helpers ---
const blobToBase64 = (blob) => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve(reader.result.split(',')[1]);
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
};

// --- AI Services (Gemini) ---

// 1. Text-only Translation (Manual Input)
const translateTextWithGemini = async (text, sourceLangName, targetLangName) => {
  if (!text || !text.trim()) return { transcript: text, translation: "" };

  const prompt = `
    Role: Professional Medical Interpreter.
    Task: Translate the text from ${sourceLangName} to ${targetLangName}.
    Input Text: "${text}"
    Output: JSON object with keys "translation" (string).
  `;

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ parts: [{ text: prompt }] }],
          generationConfig: { responseMimeType: "application/json" }
        }),
      }
    );

    const result = await response.json();
    const json = JSON.parse(result.candidates[0].content.parts[0].text);
    return { transcript: text, translation: json.translation };
  } catch (error) {
    console.error("Text Translation Error:", error);
    return { transcript: text, translation: "Translation Error" };
  }
};

// 2. Multimodal Audio Processing (Audio -> Transcript + Translation)
const processAudioWithGemini = async (audioBase64, sourceLangName, targetLangName) => {
  const prompt = `
    Role: Professional Medical Interpreter.
    Task: 
    1. Transcribe the audio spoken in ${sourceLangName} exactly.
    2. Translate the transcription to ${targetLangName}.
    
    Guidelines:
    - Capture medical terms accurately.
    - If the audio is silent or unintelligible, return null for both.
    
    Output Schema (JSON):
    {
      "transcript": "The original text spoken in the audio",
      "translation": "The translated text in ${targetLangName}"
    }
  `;

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{
            parts: [
              { text: prompt },
              {
                inlineData: {
                  mimeType: "audio/wav",
                  data: audioBase64
                }
              }
            ]
          }],
          generationConfig: { responseMimeType: "application/json" }
        }),
      }
    );

    if (!response.ok) throw new Error(`Gemini API Error: ${response.status}`);

    const result = await response.json();
    if (!result.candidates || !result.candidates[0].content) {
      throw new Error("No AI response generated");
    }

    const jsonText = result.candidates[0].content.parts[0].text;
    return JSON.parse(jsonText);
  } catch (error) {
    console.error("Audio Processing Error:", error);
    throw error;
  }
};

// --- Components ---

const Button = ({ children, onClick, variant = 'primary', className = '', disabled = false, icon: Icon }) => {
  const baseStyle = "flex items-center justify-center gap-2 px-4 py-3 rounded-xl font-semibold transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed active:scale-95 shadow-sm";
  const variants = {
    primary: "bg-blue-600 text-white hover:bg-blue-700 shadow-blue-200",
    secondary: "bg-white text-slate-700 border border-slate-200 hover:bg-slate-50 hover:border-slate-300",
    danger: "bg-red-50 text-red-600 hover:bg-red-100 border border-red-100",
    ghost: "bg-transparent text-slate-500 hover:text-blue-600 hover:bg-blue-50"
  };

  return (
    <button 
      onClick={onClick} 
      disabled={disabled}
      className={`${baseStyle} ${variants[variant]} ${className}`}
    >
      {Icon && <Icon size={20} />}
      {children}
    </button>
  );
};

const LanguageSelector = ({ label, value, onChange, options }) => (
  <div className="flex flex-col gap-1.5 flex-1 min-w-[140px]">
    <label className="text-xs font-semibold uppercase tracking-wider text-slate-500 ml-1">
      {label}
    </label>
    <div className="relative">
      <select
        value={value}
        onChange={(e) => onChange(e.target.value)}
        className="w-full appearance-none bg-white border border-slate-200 text-slate-700 py-3 pl-4 pr-10 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent font-medium shadow-sm cursor-pointer hover:border-blue-300 transition-colors"
      >
        {options.map((lang) => (
          <option key={lang.code} value={lang.code}>
            {lang.flag} {lang.name}
          </option>
        ))}
      </select>
      <div className="absolute inset-y-0 right-0 flex items-center pr-3 pointer-events-none text-slate-400">
        <Languages size={16} />
      </div>
    </div>
  </div>
);

const TranscriptCard = ({ 
  title, 
  text, 
  setText,
  langCode, 
  isPlaceholder, 
  isTranslating, 
  onSpeak, 
  colorInfo,
  editable = false,
  isRecording = false,
  inputRef
}) => {
  const [copied, setCopied] = useState(false);

  const handleCopy = () => {
    if (!text || isPlaceholder) return;
    navigator.clipboard.writeText(text);
    setCopied(true);
    setTimeout(() => setCopied(false), 2000);
  };

  return (
    <div className={`flex flex-col h-full bg-white rounded-2xl shadow-sm border border-slate-100 overflow-hidden ${isTranslating ? 'ring-2 ring-blue-100' : ''}`}>
      <div className={`px-5 py-3 border-b border-slate-100 flex justify-between items-center ${colorInfo.bg}`}>
        <h3 className={`font-semibold text-sm ${colorInfo.text}`}>{title}</h3>
        <div className="flex gap-1">
          <button 
            onClick={handleCopy}
            disabled={isPlaceholder}
            className={`p-1.5 rounded-lg hover:bg-white/50 transition-colors ${colorInfo.text} disabled:opacity-30`}
            title="Copy text"
          >
            {copied ? <Check size={16} /> : <Copy size={16} />}
          </button>
          <button 
            onClick={() => onSpeak(text, langCode)}
            disabled={isPlaceholder}
            className={`p-1.5 rounded-lg hover:bg-white/50 transition-colors ${colorInfo.text} disabled:opacity-30`}
            title="Read aloud"
          >
            <Volume2 size={16} />
          </button>
        </div>
      </div>
      <div className="flex-1 relative min-h-[160px]">
        {editable ? (
          <textarea
            ref={inputRef}
            value={text}
            onChange={(e) => setText(e.target.value)}
            placeholder={isRecording ? "Recording in progress..." : "Type here or hold mic to speak..."}
            className={`w-full h-full p-5 resize-none focus:outline-none focus:bg-blue-50/30 transition-colors text-lg leading-relaxed text-slate-800 ${isRecording ? 'placeholder:text-red-500 animate-pulse bg-red-50/50' : 'placeholder:text-slate-400'}`}
          />
        ) : (
          <div className="p-5 h-full overflow-y-auto relative">
            {isTranslating ? (
              <div className="absolute inset-0 flex flex-col items-center justify-center bg-white/80 z-10 backdrop-blur-sm">
                <Loader2 className="animate-spin text-blue-500 mb-2" size={32} />
                <span className="text-sm font-medium text-blue-600 animate-pulse">Processing Audio...</span>
              </div>
            ) : null}
            
            {text ? (
              <p className="text-lg leading-relaxed text-slate-800 whitespace-pre-wrap">{text}</p>
            ) : (
              <p className="text-slate-400 italic text-center mt-10">
                Translation will appear here...
              </p>
            )}
          </div>
        )}
      </div>
    </div>
  );
};

// --- Main App Component ---

export default function App() {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const [transcript, setTranscript] = useState("");
  const [translatedText, setTranslatedText] = useState("");
  
  const [sourceLang, setSourceLang] = useState('en-US');
  const [targetLang, setTargetLang] = useState('es-ES');
  const [error, setError] = useState("");
  
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const textAreaRef = useRef(null);

  // -- Audio Recording Logic --
  const startRecording = async () => {
    setError("");
    setTranscript("");
    setTranslatedText("");
    audioChunksRef.current = [];

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // Stop all tracks to release mic
        stream.getTracks().forEach(track => track.stop());
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        if (audioBlob.size > 0) {
          handleAudioProcess(audioBlob);
        } else {
          setIsRecording(false);
          setIsProcessing(false);
        }
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (err) {
      console.error("Mic Error:", err);
      setError("Microphone access denied. Please type your message.");
      setIsRecording(false);
      if (textAreaRef.current) textAreaRef.current.focus();
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop(); // This triggers onstop above
      setIsRecording(false);
      setIsProcessing(true); // Show loader while Gemini works
    }
  };

  // -- AI Processing Logic --
  const handleAudioProcess = async (audioBlob) => {
    try {
      const base64Audio = await blobToBase64(audioBlob);
      const sLang = LANGUAGES.find(l => l.code === sourceLang)?.name || "English";
      const tLang = LANGUAGES.find(l => l.code === targetLang)?.name || "English";

      const result = await processAudioWithGemini(base64Audio, sLang, tLang);
      
      setTranscript(result.transcript || "");
      setTranslatedText(result.translation || "");
    } catch (err) {
      setError("Failed to process audio. Please try again or type.");
      console.error(err);
    } finally {
      setIsProcessing(false);
    }
  };

  // -- Manual Text Logic --
  const handleManualTranslate = async (text) => {
    setTranscript(text);
    if (!text.trim()) {
        setTranslatedText("");
        return;
    }
    
    // Simple debounce could be added here, but for now we'll just process
    // We don't want to spam the API on every keystroke if it's not debounced
    // For this prototype, let's just wait for user to stop typing or use a button? 
    // Actually, let's debounce.
  };

  // Debounced Text Translation
  useEffect(() => {
    const timer = setTimeout(async () => {
        if (transcript && !isRecording && !isProcessing) {
             // Only translate if it looks like manual input (not empty, not currently processing audio)
             // We check if translatedText matches to avoid re-translating the result of an audio process
             // But actually, manual edits should re-translate.
             const sLang = LANGUAGES.find(l => l.code === sourceLang)?.name || "English";
             const tLang = LANGUAGES.find(l => l.code === targetLang)?.name || "English";
             
             // Small optimization: don't re-call if we just got this from audio
             // We can't easily track that state without complexity, so we'll just call the lightweight text API.
             // It's fast.
             if (transcript.length > 1) { // minimum length
                 const res = await translateTextWithGemini(transcript, sLang, tLang);
                 setTranslatedText(res.translation);
             }
        }
    }, 1000);
    return () => clearTimeout(timer);
  }, [transcript, sourceLang, targetLang]);


  const speakText = (text, lang) => {
    if (!text) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = lang;
    utterance.rate = 0.9;
    const voices = window.speechSynthesis.getVoices();
    const voice = voices.find(v => v.lang === lang) || voices.find(v => v.lang.startsWith(lang.split('-')[0]));
    if (voice) utterance.voice = voice;
    window.speechSynthesis.speak(utterance);
  };

  const clearAll = () => {
    setTranscript("");
    setTranslatedText("");
    setError("");
  };

  return (
    <div className="min-h-screen bg-slate-50 font-sans text-slate-900 pb-12">
      {/* Header */}
      <header className="bg-white border-b border-slate-200 sticky top-0 z-10">
        <div className="max-w-4xl mx-auto px-4 py-4 flex items-center justify-between">
          <div className="flex items-center gap-3">
            <div className="bg-blue-600 p-2 rounded-lg text-white">
              <Stethoscope size={24} />
            </div>
            <div>
              <h1 className="text-xl font-bold text-slate-800 leading-tight">MediTranslate AI</h1>
              <p className="text-xs text-slate-500 font-medium">Powered by Gemini Multimodal Audio</p>
            </div>
          </div>
          <div className="flex items-center gap-2">
            <span className="hidden md:flex items-center gap-1.5 px-3 py-1 bg-green-50 text-green-700 text-xs font-bold rounded-full border border-green-100">
              <ShieldCheck size={12} />
              HIPAA Compliant Mode
            </span>
          </div>
        </div>
      </header>

      <main className="max-w-4xl mx-auto px-4 py-6 space-y-6">
        
        {/* Error Banner */}
        {error && (
          <div className="bg-amber-50 text-amber-800 px-4 py-3 rounded-xl border border-amber-200 flex items-center justify-between animate-in slide-in-from-top-2">
            <div className="flex items-center gap-2 text-sm font-medium">
              <Activity size={16} />
              {error}
            </div>
            <button onClick={() => setError("")} className="text-amber-600 hover:text-amber-800">
              <X size={16} />
            </button>
          </div>
        )}

        {/* Controls */}
        <section className="grid grid-cols-1 md:grid-cols-[1fr_auto_1fr] gap-4 items-end bg-white p-5 rounded-2xl shadow-sm border border-slate-200">
          <LanguageSelector 
            label="Doctor / Speaker" 
            value={sourceLang} 
            onChange={(val) => setSourceLang(val)} 
            options={LANGUAGES}
          />
          
          <div className="flex justify-center pb-1">
            <button 
              onClick={() => {
                const temp = sourceLang;
                setSourceLang(targetLang);
                setTargetLang(temp);
                const tempText = transcript;
                setTranscript(translatedText);
                setTranslatedText(tempText);
              }}
              className="p-2 rounded-full bg-slate-100 text-slate-500 hover:bg-blue-50 hover:text-blue-600 transition-colors"
              title="Swap Languages"
            >
              <RotateCcw size={18} />
            </button>
          </div>

          <LanguageSelector 
            label="Patient / Listener" 
            value={targetLang} 
            onChange={(val) => setTargetLang(val)} 
            options={LANGUAGES}
          />
        </section>

        {/* Action Bar */}
        <section className="flex flex-col sm:flex-row gap-6 justify-center items-center py-4">
           {/* Dynamic Recording Button */}
           <button
            onClick={isRecording ? stopRecording : startRecording}
            disabled={isProcessing}
            className={`
              relative flex items-center justify-center w-24 h-24 rounded-full shadow-xl transition-all duration-300
              ${isProcessing 
                ? 'bg-slate-100 cursor-not-allowed scale-95' 
                : isRecording 
                  ? 'bg-red-500 text-white hover:bg-red-600 ring-4 ring-red-100 scale-110' 
                  : 'bg-gradient-to-br from-blue-600 to-indigo-600 text-white hover:shadow-blue-300/50 hover:scale-105'
              }
            `}
          >
            {isRecording && (
              <span className="absolute animate-ping inline-flex h-full w-full rounded-full bg-red-400 opacity-20"></span>
            )}
            
            {isProcessing ? (
              <Loader2 size={32} className="animate-spin text-slate-400" />
            ) : isRecording ? (
              <div className="flex flex-col items-center">
                <Square size={32} fill="currentColor" />
                <span className="text-[10px] font-bold mt-1 uppercase tracking-wide">Stop</span>
              </div>
            ) : (
              <div className="flex flex-col items-center">
                <Mic size={32} />
                <span className="text-[10px] font-bold mt-1 uppercase tracking-wide">Speak</span>
              </div>
            )}
          </button>
          
          <div className="text-center sm:text-left space-y-1">
            <p className="text-lg font-bold text-slate-700">
              {isProcessing 
                ? "Processing Audio..." 
                : isRecording 
                  ? "Listening..." 
                  : "Tap to Speak"
              }
            </p>
            <div className="text-sm text-slate-500 flex items-center justify-center sm:justify-start gap-2">
              {isProcessing ? (
                 <span className="flex items-center gap-1 text-blue-600">
                   <Wand2 size={14} /> AI is transcribing & translating
                 </span>
              ) : isRecording ? (
                 <span>Recording... tap to finish</span>
              ) : (
                 <span>High-accuracy AI Speech Recognition</span>
              )}
            </div>
          </div>

          <div className="flex-1"></div>
          
          <Button variant="secondary" onClick={clearAll} className="w-full sm:w-auto">
            New Session
          </Button>
        </section>

        {/* Transcripts Grid */}
        <section className="grid grid-cols-1 md:grid-cols-2 gap-6">
          <TranscriptCard 
            title="Original Transcript (Editable)"
            text={transcript}
            setText={handleManualTranslate}
            langCode={sourceLang}
            isPlaceholder={!transcript}
            onSpeak={speakText}
            colorInfo={{ bg: 'bg-slate-50', text: 'text-slate-600' }}
            editable={true}
            isRecording={isRecording}
            inputRef={textAreaRef}
          />
          
          <TranscriptCard 
            title="AI Translation"
            text={translatedText}
            langCode={targetLang}
            isPlaceholder={!translatedText}
            isTranslating={isProcessing} // Show loading state on right card while processing
            onSpeak={speakText}
            colorInfo={{ bg: 'bg-blue-50', text: 'text-blue-700' }}
          />
        </section>

        {/* Disclaimer Footer */}
        <footer className="pt-6 border-t border-slate-200 mt-6">
          <div className="bg-yellow-50 rounded-xl p-4 flex gap-3 items-start">
             <div className="text-yellow-600 mt-0.5">
               <ShieldCheck size={20} />
             </div>
             <div className="text-xs text-yellow-800 leading-relaxed">
               <strong>Disclaimer:</strong> {DISCLAIMER}
               <br/>
               <span className="opacity-75 mt-1 block">
                 Audio is processed securely in real-time by Google Gemini.
               </span>
             </div>
          </div>
        </footer>
      </main>
    </div>
  );
}